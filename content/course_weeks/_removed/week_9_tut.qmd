---
title: "9 - Difference-in-Differences"
linktitle: "9 - Difference-in-Differences"
output:
  blogdown::html_page:
    toc: true
menu:
  example:
    parent: Course content
    weight: 1
type: docs
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width = 6, fig.asp = 0.618, fig.align = "center", fig.retina = 3, out.width = "75%")
set.seed(11)
options("digits" = 2, "width" = 150)
options(dplyr.summarise.inform = FALSE)

# custom ggplot theme
# colors from TUHH brand identitiy
tuhh_colors <- c("#D0D0CE", "#00C1D4", "#FF4F4F", "#5AFFC5",
                 "#FFDE36", "#143BFF", "#FF7E15", "#FFAEA2")

# initialise theme
cds_theme <- ggthemr::define_palette(
  swatch = tuhh_colors,
  gradient = c(lower = "#FFAEA2", upper = "#00C1D4"),
  background = "#0F2231",
  line = c("#FFFFFF", "#FFFFFF"),
  text = c("#FFFFFF", "#FFFFFF"),
  gridline = c(ggplot2::alpha("#D0D0CE", 0.2), 
               ggplot2::alpha("#D0D0CE", 0.4))
)

# set theme
ggthemr::ggthemr(cds_theme, type = "outer")

# source custom DAG theme
source(paste0(here::here(), "/code/dag_theme.R"))
```

## Slides & Recap

<iframe style="width: 100%; height: 45vw; max-height: 50vh;" frameborder="0" allowfullscreen src="https://tuhhstartupengineers-classroom.github.io/ss24-causal-data-science/slides/08_did.html">

</iframe>


So far, we have primarily discussed cross-sectional data, where each unit is observed only once. However, sometimes you can observe units over multiple time periods, resulting in panel data. This allows us to see how a unit changes before and after a treatment. When randomization isn't feasible, panel data is the best alternative for identifying causal effects. The most well-known method for estimating this effect is called difference-in-differences (DiD).

## Panel Data

In marketing, randomization is often impractical because you cannot always control who receives the treatment. For instance, let's say you decide to place billboards in a city to advertise your app, aiming to measure the resulting number of downloads attributed to these billboards. You will advertise in some cities but not in others, creating a geo experiment. Additionally, you will track several time-invariant covariates:

- $age_i$: age average in city $i$
- $population\_size_i$: integer indicating population size of city $i$
- $user\_share_i$: initial share of app users prior to observation period in city $i$
- $competitor\_price_i$: average of competitor app price in that given area

Unlike your competitor, your app is free to download, and you plan to generate revenue within the app. Our observed units are cities $i$ over multiple time periods $t$. Let's have a look at the [data](https://cloud.tuhh.de/index.php/s/etes53YbZxiYtME).


```{r}
#| message: false
#| warning: false

# Load tidyverse
library(tidyverse)

# Read data
df <- readRDS("mkt_panel.rds")

# Print first lines
print(df |> head(10))
```

We see that for city $i=1$, we have eight months with $post = 0$ and 1 month with $post = 1$. The outcome changes over time but the covariates are time invariant. Please also note that the treatment indicator indicates whether a unit was "ever" treated.

When counting the number of control and treatment units per period, we'll see that we have a complete panel without any missing data.

```{r}
# Panel data overview
df_piv <- df |>
  count(month, ever_treated, post) |> 
  pivot_wider(
    names_from = "ever_treated",
    values_from = "n",
    names_prefix = "ever_treated_"
    )

# Print
print(df_piv)
```

## Basic differences-in-differences

Not always you will have several pre-treatment periods and DiD already works when you only observe one period before and one period after the treatment. So let's image that scenario and later re-introduce the other pre-treatment periods.

```{r}
# Last pre-treatment and post-treatment period
df_2p <- df |> filter(month %in% 8:9)

# Print
print(df_2p |> count(month, ever_treated, post))
```

Because we observe both control and treated units before and after the treatment, we can compute the treatment effect $\tau_{\text{DiD}}$ using the difference-in-differences method. This involves first calculating the difference in outcomes between the treated and control groups after the treatment, then subtracting the difference in outcomes between these groups before the treatment. This double differencing helps isolate the treatment effect.

$$
\begin{aligned}
\tau_{\text{DiD}} = \underbrace{\mathbb{E}[Y_{i,1} | D_i=1] - \mathbb{E}[Y_{i,1} | D_i=0]}_{\text{difference in post-treatment}} \\ - \underbrace{(\mathbb{E}[Y_{i,0} | D_i=1] - \mathbb{E}[Y_{i,0} | D_i=0])}_{\text{difference in pre-treatment}}
\end{aligned}
$$

In a slightly different and cleaned up notation, we see that the difference we obtain is only attributed to the treatment.

::: {.grid}

::: {.g-col-2}
:::


::: {.g-col-8}

| Group           | Time | Outcome                   | 1st Difference | DiD |
|-----------------|------|---------------------------|----------------|-----|
| Treatment (D=1) | 0    | $Y= Y_{T=0, D=1}$         |                |     |
|                 | 1    | $Y = Y_{T=0,D=1} + T + D$ | $T +D$         |     |
|                 |      |                           |                | $D$ |
| Control (D=0)   | 0    | $Y = Y_{T=0, D=0}$        |                |     |
|                 | 1    | $Y = Y_{T=0, D=0} + T$    | $T$            |     |

:::

::: {.g-col-2}
:::

:::

[**Task 1:**]{style="color:#FF7E15"} With the help of the formula/table, compute $\tau_{\text{DiD}}$. What is the interpretation with regard to our example?

```{r}
# ...
```

```{r}
#| include: false

# Step 1: group by treatment group and period
did_p2 <- df_2p |> 
  group_by(ever_treated, post) |> 
  summarise(
    y = mean(downloads)
  ) |> 
  ungroup()

print(did_p2)
```

```{r}
# Step 2: Extract values and doubly differencing
with(did_p2, {
  y_00 <- y[ever_treated == 0 & post == 0]
  y_01 <- y[ever_treated == 0 & post == 1]
  y_10 <- y[ever_treated == 1 & post == 0]
  y_11 <- y[ever_treated == 1 & post == 1]
  
  (y_11 - y_10) - (y_01 - y_00)
})
```

Alternatively, we can use regression-based approaches to estimate the treatment effect. Two different approaches yielding equivalent results are:

1. Two-way fixed effects (TWFE).

$$
Y_{i,t} = \alpha_i + \gamma_t + \tau_{\text{DiD}} (D_i \times t) + \epsilon_{i,t}
$$

2. Regression with treatment and time dummy, as well as interaction of treatment and time.

$$
Y_{i,t} = \alpha + \beta D_i + \gamma t + \tau_{\text{DiD}} (D_i \times t) + \epsilon_{i,t}
$$
[**Task 2:**]{style="color:#FF7E15"} Perform both approaches and report the estimated coefficient.

```{r}
# ...
```

```{r}
# ...
```

```{r}
#| include: false

# (1)
mod_1 <- lm(downloads ~ ever_treated:post + as.factor(city) + as.factor(month), data = df_2p)

# Coefficient
coef_mod_1 <- mod_1$coefficients["ever_treated:post"]
sprintf("%.2f", coef_mod_1)
```

```{r}
#| include: false

# (2)
mod_2 <- lm(downloads ~ ever_treated*post, data = df_2p)
summary(mod_2)
```

For two-way fixed effects estimation, we can generally also use the `lm()` command which we have used for so many applications already. However, it is recommended to use the `fixest` package due to its increased speed and focus on fixed effects. As it is the workhorse of many other packages, let's get it installed.

```{r}
#| eval: false

install.packages("fixest")
```

The formula notation is slightly different as we separate the fixed effects using the | operator. This approach allows the algorithm to converge faster, and the fixed effects will not appear in the regression summary. Since fixed effects are typically not of primary interest and we often have a large number of them, this simplification is quite convenient.

```{r}
#| message: false
#| warning: false
#| code-fold: true

# Faster way for (1)
library(fixest)
summary(feols(downloads ~ ever_treated:post | city + month, data = df_2p))
```

## Parallel trends

Here, where we only have two time period, we need to rely on one assumption to hold: the **parallel trends assumption**. Opposed to methods where we just know one outcome - the "after" outcome, regardless of whether a unit received or did not receive treatment - we do not have to assume that the potential outcomes are equal $(Y_1(0)-Y_0(0)) \perp\!\!\!\perp T$. That is a big difference, because do not have to assume that observation units are similar in all their characteristics. Instead DiD hinges on a different assumption, the parallel trends assumption. It says that, in absence of treatment for both groups, they would be expected to evolve similarly over time. In other words, we do not expect the potential outcome to be similar, but only the change of outcomes from before to after. It implies that there is no factor that has only an impact on just one of the groups.

$$
\mathbb{E}[Y_{i,t=1}(0) - Y_{i,t=0}(0) | D_i=1] = \mathbb{E}[Y_{i,t=1}(0) - Y_{i,t=0}(0) | D_i=0]
$$

While the parallel trends assumption is generally untestable, in the case with only two periods, we are particularly in the dark.

Graphically, what we assume is that the treated line would have evolved similarly to the control line - as depicted by the dotted line. What can we do to increase the plausibility of this assumption?

```{r}
#| code-fold: true

y10 <- did_p2[did_p2$ever_treated==1 & did_p2$post==0, ]$y
y01 <- did_p2[did_p2$ever_treated==0 & did_p2$post==1, ]$y
y00 <- did_p2[did_p2$ever_treated==0 & did_p2$post==0, ]$y

data_cf <- tibble(
  x = c(0, 1),
  y = c(y10, y10 + (y01-y00))
)

ggplot(did_p2, aes(x = post, y = y, group = ever_treated, color = as.factor(ever_treated))) +
  geom_point() +
  geom_line() +
  geom_line(data = data_cf, aes(x=x, y=y, group = NA), color="#5AFFC5", linetype = "dotted") +
  geom_vline(xintercept = .5, linetype = "dashed") +
  scale_x_continuous(breaks=c(0,1)) +
  theme(legend.position = "bottom")
```

## Testing for parallel trends

There is some remedy when we are able to observe multiple periods prior to the treatment. By comparing trends before treatment between the treatment and control groups, researchers aim to demonstrate that there was no significant difference prior to the treatment. The logic is that if there was no difference before treatment, any difference observed after the treatment is likely due to the treatment itself.

However, even that cannot provide full certainty about the parallel trends assumption. There may still be unobserved factors that could affect the treatment. Nevertheless, event studies are a useful tool for arguing that the treatment and control groups are comparable.

Let's now switch back to the dataset with multiple pre-treatment periods and begin by plotting the observed outcomes over time. This will help us determine if there are converging or diverging trends between the treatment and control groups. By visualizing these trends, we can already assess whether the parallel trends assumption holds before the treatment.

```{r}
#| code-fold: true

# Outcomes across time by group
df |> 
  ggplot(aes(
    x = month,
    y = downloads,
    fill = as.factor(ever_treated),
    color = as.factor(ever_treated)
  )) + 
  stat_summary(fun.data = mean_se, geom = "point", alpha = .8) +
  stat_summary(fun.data = mean_se, geom = "line", alpha = .8) +
  stat_summary(fun.data = mean_se, geom = "ribbon", alpha = .2, color = NA) +
  geom_vline(xintercept = 8.5, linetype = "dashed") +
  scale_x_continuous(breaks=1:9) +
  theme(legend.position = "bottom")
```

At the first glance, prior to the treatment, the outcomes seem to evolve in parallel. However, a better way is to actually perform statistical tests and check the hypothesis that the evolution of both groups is parallel. For each difference between two pre-treatment periods, the should be no difference in the evolution of the outcomes across the treatment groups.

[**Task 3a:**]{style="color:#FF7E15"} Subset the data so you can perform test for pre-trends between the pre-treatment months 7 and 8 using the TWFE approach from above.

```{r}
# ...
```

```{r}
#| include: false

df_placebo <- df |> 
  filter(month %in% c(7, 8)) |> 
  mutate(post = if_else(month == 8, 1, 0))

summary(feols(downloads ~ ever_treated:post | city + month, data = df_placebo))
```

[**Task 3b:**]{style="color:#FF7E15"} Subset the data so you can perform test for pre-trends between the pre-treatment months 3 and 8 using the TWFE approach from above.

```{r}
# ...
```

```{r}
#| include: false

df_placebo <- df |> 
  filter(month %in% c(8, 3)) |> 
  mutate(post = if_else(month == 8, 1, 0))

feols(downloads ~ ever_treated:post | city + month, data = df_placebo)
```

With this approach, you would have to iterate through quite a lot of combinations. Another approach would be to add "fake" post columns to the data frame and interact them with the treatment indicator.

[**Task 4:**]{style="color:#FF7E15"} Subset the data so you can perform test for pre-trends between ALL two arbitrary pre-treatment periods using the TWFE approach from above. You'll need to create new columns with e.g. `post_t = if_else(month == t, 1, 0)`, where `t` is a treatment period and introduce new interactions into the formula.

```{r}
# ...
```

```{r}
#| include: false

df_placebo_all <- df |> 
  mutate(
    post_1 = if_else(month == 1, 1, 0),
    post_2 = if_else(month == 2, 1, 0),
    post_3 = if_else(month == 3, 1, 0),
    post_4 = if_else(month == 4, 1, 0),
    post_5 = if_else(month == 5, 1, 0),
    post_6 = if_else(month == 6, 1, 0),
    post_7 = if_else(month == 7, 1, 0),
    post_8 = if_else(month == 8, 1, 0)
    )

feols(downloads ~ 
        ever_treated:post_1 +
        ever_treated:post_2 +
        ever_treated:post_3 +
        ever_treated:post_4 +
        ever_treated:post_5 +
        ever_treated:post_6 +
        ever_treated:post_7 +
        #ever_treated:post_8 + reference value
        ever_treated:post | city + month, data = df_placebo_all)
```

An even more programmatic way to test for pre-trends is to run an event study to perform the tests all in one command. We only have to slightly change the input. Instead of the single treatment indicator `ever_treated:post`, which is only active for the treated group after treatment, we include several interactions which cover all periods for the treated group.

We can do so with the help of `i()` from the `fixest` package and a newly created variable that measures the time distance to the treatment period.

```{r}
#| include: false

# Create time distance column
treat_month <- 9
df <- df |> mutate(time_to_treat = if_else(ever_treated == 1, month - treat_month, 0))

evt_stdy <- feols(downloads ~ i(time_to_treat, ever_treated, ref = -1) | city + month, data = df)
summary(evt_stdy)

```

Using `iplot()` we can visualize the multiple treatment effects. Any treatment effect prior to the treatment is a big cause of concern with regards to the parallel trends assumption.

```{r}
#| eval: false
# Plot event study
iplot(evt_stdy)
```

```{r}
#| echo: false

ggfixest::ggiplot(evt_stdy)
```


## Conditional parallel trends

Now, we have seen that we cannot assume parallel trends - there are significant differences in the evolution of outcomes. But what can we do to increase the plausibility of assuming parallel trends? One approach that is widely been used in practice is the inclusion of covariates. But as you have learned in the lecture, you have to be extremely careful.

What you obtain then is the conditional parallel trends assumption, which is the assumption of parallel trends conditional on covariates.

$$
\mathbb{E}[Y_{i,t=1}(0) - Y_{i,t=0}(0) | T_i=1, \mathbf{X_i}] = \mathbb{E}[Y_{i,t=1}(0) - Y_{i,t=0}(0) | T_i=0, \mathbf{X_i}] \quad
$$



[**Task 5:**]{style="color:#FF7E15"} Include the covariates into the event study and consider that they have time-varying effects.

```{r}
# ...
```

```{r}
#| include: false

# Time-invariant, therefore multicollinearity.
evt_stdy_cond_1 <- feols(
  downloads ~ i(time_to_treat, ever_treated, ref = -1) +
    age + user_share + population_size + competitor_price
  | city + month, data = df)
evt_stdy_cond_1
```



```{r}
#| include: false

# Time-invariant, but time-varying effects.
evt_stdy_cond_2 <- feols(
  downloads ~ i(time_to_treat, ever_treated, ref = -1) +
    age:month + user_share:month + population_size:month + competitor_price: month
  | city + month, data = df)
evt_stdy_cond_2
```

```{r}
#| eval: false
# Plot event study
iplot(evt_stdy_cond_2)
```

```{r}
#| include: false

ggfixest::ggiplot(evt_stdy_cond_2)
```

## ATT conditional on covariates

### TWFE

[**Task 6:**]{style="color:#FF7E15"} Use the TWFE approach to estimate the ATT by under the assumption of parallel trend conditional on the covariates.

```{r}
# ...
```

```{r}
#| include: false

feols(downloads ~ post:ever_treated +
                    age:month + user_share:month + population_size:month + competitor_price: month
                  | city + month, data = df)
```

### Doubly robust estimator

During the last weeks we have already learned the advantages of doubly robust estimation and in fact, there is a doubly robust DiD estimator proposed by [Sant’Anna and Zhao, 2020](https://www.sciencedirect.com/science/article/abs/pii/S0304407620301901) and implemented in the `DRDID` package. 

```{r}
#| eval: false

install.packages("DRDID")
```

```{r}
library(DRDID)

drdid(
  yname = "downloads",
  tname = "post",
  idname = "city",
  dname = "ever_treated",
  xformla = ~age+user_share+population_size+competitor_price,
  data = df_2p
)
```

[**Task 7:**]{style="color:#FF7E15"} Following the same syntax, use the outcome regression adjustment with `ordid()` and the inverse probability weighting approach `ipwdid()` to estimate the treatment effect.

```{r}
# ...
```

### Outcome regression

```{r}
#| include: false

ordid(
  yname = "downloads",
  tname = "post",
  idname = "city",
  dname = "ever_treated",
  xformla = ~age+user_share+population_size+competitor_price,
  data = df_2p
)
```

### Inverse probability weighting regression

```{r}
#| include: false

ipwdid(
  yname = "downloads",
  tname = "post",
  idname = "city",
  dname = "ever_treated",
  xformla = ~age+user_share+population_size+competitor_price,
  data = df_2p
)
```


## Assignment

Coming soon.

::: assignment
Coming soon.
:::

