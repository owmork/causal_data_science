---
title: "11 - Synthetic Control & Regression Discontinuity"
linktitle: "11 - Synthetic Control & Regression Discontinuity"
output:
  blogdown::html_page:
    toc: true
menu:
  example:
    parent: Course content
    weight: 1
type: docs
editor_options: 
  chunk_output_type: console
editor: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width = 6, fig.asp = 0.618, fig.align = "center", fig.retina = 3, out.width = "75%")
set.seed(11)
options("digits" = 2, "width" = 150)
options(dplyr.summarise.inform = FALSE)

# custom ggplot theme
# colors from TUHH brand identitiy
tuhh_colors <- c("#D0D0CE", "#00C1D4", "#FF4F4F", "#5AFFC5",
                 "#FFDE36", "#143BFF", "#FF7E15", "#FFAEA2")

# initialise theme
cds_theme <- ggthemr::define_palette(
  swatch = tuhh_colors,
  gradient = c(lower = "#FFAEA2", upper = "#00C1D4"),
  background = "#0F2231",
  line = c("#FFFFFF", "#FFFFFF"),
  text = c("#FFFFFF", "#FFFFFF"),
  gridline = c(ggplot2::alpha("#D0D0CE", 0.2), 
               ggplot2::alpha("#D0D0CE", 0.4))
)

# set theme
ggthemr::ggthemr(cds_theme, type = "outer")

# source custom DAG theme
source(paste0(here::here(), "/code/dag_theme.R"))
```

# Slides & Recap

<iframe style="width: 100%; height: 45vw; max-height: 50vh;" frameborder="0" allowfullscreen src="https://tuhhstartupengineers-classroom.github.io/ss24-causal-data-science/slides/09_synth_c.html">

</iframe>

Over the past two weeks, we've explored how to use panel data to estimate causal effects with variations of the difference-in-differences estimator. This week, we'll dive into another popular estimation technique: the synthetic control (SC) method. Originally designed for scenarios with very few treated units—often just one, like a single country—this method constructs a synthetic control unit by combining control units. This synthetic unit closely replicates the behavior of the treated unit before the intervention and acts as a counterfactual after the treatment. When the treated unit and the synthetic control unit align perfectly, we can relax the parallel trends assumption.

# Practical example

## Exploration

Consider the following example: you are working at a ride-sharing platform and you want to understand the effect of introducing a new feature on revenue, i.e. let's say the introduction of self-driving cars.
[^1]

[^1]: Inspired by: https://matteocourthoud.github.io/post/synth/

Let's directly take a look at the [data](https://cloud.tuhh.de/index.php/s/dcTRYT6Rp7JRxg8).

```{r}
#| message: false
#| warning: false

library(tidyverse)

ride <- readRDS("ride.rds")

print(head(ride))
```

As we approach the end of this module, I'll be providing less guidance. Therefore, similar to last week, let's dive into some data exploration.

[**Task 1:**]{style="color:#FF7E15"} Answer the following questions:

-   How many periods did we observe?
-   How many units did we observe?
-   How many units are in the treatment and how many are in the control group?
-   What is the treatment period?

```{r}
#| code-fold: true

# Exploration
# How many pre- and post periods?
T_pre <- n_distinct(ride[ride$post == 0, ]$period)
T_post <- n_distinct(ride[ride$post == 1, ]$period)

# How many units?
N1 <- n_distinct(ride[ride$treated == 1, ]$city)
N0 <- n_distinct(ride[ride$treated == 0, ]$city)

# What is first treatment period?
T0 <- min(ride[ride$post == 1, ]$period)

print(c(T_pre, T_post, N1, N0))
print(T0)
```

[**Task 2:**]{style="color:#FF7E15"} Plot the revenue evolution over time.

```{r}
#| code-fold: true
#| warning: false

# Revenue over time
ggplot(
  ride,
  aes(
    x = period,
    y = revenue,
    group = city,
    color = factor(treated),
    linewidth = factor(treated)
  )) +
  geom_line(aes(alpha = factor(treated))) + 
  geom_vline(xintercept = T0, linetype = "dashed") + 
  scale_alpha_manual(values = c(.15, 1)) +
  scale_linewidth_manual(values = c(.3, .5)) + 
  labs(color = "Treatment group", alpha = "Treatment group", linewidth = "Treatment group")
```

[**Task 3:**]{style="color:#FF7E15"} Compare the treated city to the control cities in terms of the covariate and outcome distribution.

```{r}
#| code-fold: true

# Treatment group comparison
balance_df <- ride |> 
  group_by(treated) |> 
  summarise(across(c("density", "employment", "gdp", "population", "revenue"), mean)) |> 
  ungroup()

print(balance_df)
```

## Synthetic control

As we explore the synthetic control method, we'll start by doing it manually. While you'll most likely use pre-built packages in practice, performing the calculations by hand can provide a deeper understanding of the underlying mechanics of the method.

Here is a useful perspective to consider as we approach the data:

$$
\begin{equation}
\left(
\begin{array}{c|c}
\begin{matrix}
X_{11} & X_{12} & \cdots & X_{1T_0} \\
\hline
X_{21} & X_{22} & \cdots & X_{2T_0} \\
\vdots & \vdots & \ddots & \vdots \\
X_{N1} & X_{N2} & \cdots & X_{NT_0}
\end{matrix}
&
\begin{matrix}
Y_{1T} \\
\hline
Y_{2T} \\
\vdots \\
Y_{NT}
\end{matrix}
\end{array}
\right)
\equiv
\left(
\begin{array}{c|c}
\begin{matrix}
\mathbf{X}_{1} \\
\hline
\mathbf{X}_{0}  \\
\end{matrix}
&
\begin{matrix}
Y_{1T} \\
\hline
\mathbf{Y}_{0T} \\
\end{matrix}
\end{array}
\right)
\end{equation}
$$ 

We utilize the control units, often referred to as the "donor pool," to replicate the pre-treatment observations of the treated unit. For each control unit, we assign a weight, which is then used to impute the counterfactual outcome for the treated unit. Specifically, $Y_{1T_t}(0)$ is imputed using a weighted average of $\mathbf{Y}_{0T_t}$.

For our initial step, we'll focus solely on pre-treatment outcomes, setting aside covariates for now. Our goal is to accurately reproduce the pre-treatment outcome of the treated unit by adjusting the weights assigned to the pre-treatment outcomes of the control units.

Let's begin by organizing our data into four distinct blocks:

- Pre-treatment control $\mathbf{X}_{0}$
- Pre-treatment treated $\mathbf{X}_{1}$
- Post-treatment control $Y_{0T}$
- Post-treatment treated $Y_{1T}$

Initially, we'll focus on revenue as our primary outcome variable and introduce covariates later in the analysis to refine our model.

[**Task 4:**]{style="color:#FF7E15"} Split the data and extract the for blocks.

```{r}
#| code-fold: true

# Split and extract 4 matrices
y0_pre <- ride |>
  filter(post == 0, treated == 0) |> 
  pivot_wider(id_cols = "period", names_from = "city", values_from = "revenue") |> 
  select(-period) |> 
  as.matrix()

y1_pre <- ride |>
  filter(post == 0, treated == 1) |> 
  pivot_wider(id_cols = "period", names_from = "city", values_from = "revenue") |> 
  select(-period) |> 
  as.matrix()

y0_post <- ride |>
  filter(post == 1, treated == 0) |> 
  pivot_wider(id_cols = "period", names_from = "city", values_from = "revenue") |> 
  select(-period) |> 
  as.matrix()

y1_post <- ride |>
  filter(post == 1, treated == 1) |> 
  pivot_wider(id_cols = "period", names_from = "city", values_from = "revenue") |> 
  select(-period) |> 
  as.matrix()

# Print "donor pool"
print(y0_pre)
```

## Horizontal regression

To find the synthetic control weights, $\mathbf{W}* = (w_2^*, \ldots, w_{N+1}^*)$ that minimizes $\|  \mathbf{X}_1 - \mathbf{X}_0 \mathbf{W} \|$, a simple way is to run an ordinary linear regression. At first, it might be a bit confusing, but, prior to the treatment, we can regress the treated unit on the control units and see which control units can explain the treated unit best. You just need two of the blocks you just created. 

[**Task 5:**]{style="color:#FF7E15"} Run the linear regression and print the obtained weights. What is an observation in this setup? What is the meaning of the coefficients?

```{r}
#| code-fold: true

# Weights from OLS
ols <- lm(y1_pre ~ 0 + y0_pre)
w_ols <- coef(ols)

print(as.data.frame(w_ols) |> arrange(-w_ols))
```

Having obtained the weights, we can now proceed to calculate the estimate that we are ultimately interested in, the $ATT$. For the periods following the treatment, we subtract the synthetic outcome from the observed outcome for the treated unit:

$$
\hat{\tau}_{1t} = Y_{1t} - \sum_{i=2}^{N+1} w_i^* Y_{it} \quad \forall \quad t > T_0
$$

This expression yields the treatment effect per period. By averaging across the treatment periods, you retrieve the $ATT$.

::: callout-note
Matrix multiplication with `%*%` in R performs a dot product of rows and columns, where each element of the resulting matrix is the sum of the products of corresponding elements from the rows of the first matrix and the columns of the second matrix.
This operation requires that the number of columns in the first matrix matches the number of rows in the second matrix.
:::

[**Task 6:**]{style="color:#FF7E15"} Calculate the ATT.

```{r}
#| code-fold: true

# Counterfactual / Synthetic control unit
y_sc_post <- y0_post %*% w_ols

# ATT
mean(y1_post - y_sc_post)
```

[**Task 7:**]{style="color:#FF7E15"} Calculate the pseudo-ATT before the treatment takes place. What value do you expect?

```{r}
#| code-fold: true

# Counterfactual / Synthetic control unit
y_sc_pre <- y0_pre %*% w_ols

# Pseudo-ATT
mean(y1_pre - y_sc_pre)
```

Let's plot the synthetic and observed unit.

```{r}
# Create data frame with synthetic control and treated unit
sc_vs_trt <- tibble(
  period = unique(ride$period),
  y_synth = c(y_sc_pre, y_sc_post),
  y_treat = c(y1_pre, y1_post)
) |> 
  pivot_longer(cols = c("y_synth", "y_treat"))

# Line plot with treatment date highlighted
ggplot(sc_vs_trt, aes(x = period, y = value, group = name, color = name)) +
  geom_line() +
  geom_vline(xintercept = T0, linetype = "dashed")
```

Because we will want to plot in the subsequent steps as well, let's create a function that helps us avoiding to rewrite the code.
The only thing that is variable in these lines of codes is the estimated synthetic control unit.
Check for yourself that you can reproduce the previous plot using the function.

```{r}
# Generate plot of synthetic unit and observed treated unit
plot_synth <- function(y_sc_pre, y_sc_post) {
  # Data to plot
  sc_vs_trt <- tibble(
    period = unique(ride$period), # periods (will be replicated)
    y_synth = c(y_sc_pre, y_sc_post), # synthetic outcomes
    y_treat = c(y1_pre, y1_post) # observed outcomes of treated unit
  ) |> 
    # long format for ggplot
    pivot_longer(cols = c("y_synth", "y_treat"))
  
  ggplot(sc_vs_trt,
         aes(
           x = period, 
           y = value, 
           group = name, 
           color = name)
         ) +
    geom_line() +
    geom_vline(xintercept = T0, linetype = "dashed")
}
```

## Period weights

We have successfully replicated the pre-treatment outcomes quite closely. In doing so, we've implicitly assumed that each period leading up to the treatment carries equal significance for our analysis. However, it's reasonable to consider that more recent periods might be more indicative of the trends following the treatment. To accommodate this insight, we can simply adjust our methodology to place greater emphasis on these more recent periods. This minor modification will help refine our approach and potentially yield more accurate predictions.

$$
\begin{aligned}
\mathbf{W}^* = \arg\min_{\mathbf{W}} \| \sqrt{V}\mathbf{X}_1 - \mathbf{X}_0 \mathbf{W} \|_2^2 &= \arg\min_{\mathbf{W}} [(\mathbf{X}_1 - \mathbf{X}_0 \mathbf{W})' \mathbf{V} (\mathbf{X}_1 - \mathbf{X}_0 \mathbf{W})] \\
&= \arg\min_{\mathbf{W}} \sum_{m=1}^{k} v_m \bigg( X_{1m} - \sum_{i=2}^{N+1} w_iX_{im}\bigg)^2 \\
\end{aligned}
$$ 

::: callout-note
The sweep() function in R applies an operation (such as addition, subtraction, multiplication, or division) to the rows or columns of a matrix or array, using a corresponding vector of values, effectively "sweeping" the operation across the specified margin (rows or columns) of the data. In R, the margin 1 and 2 refer to rows and columns, respectively.
:::

```{r}
# Including weights with uniform weights
a_uni <- rep(1, T_pre)
y0_pre_uni <- sweep(y0_pre, 1, a_uni, "*")
y1_pre_uni <- sweep(y1_pre, 1, a_uni, "*")

ols_uni <- lm(y1_pre_uni ~ 0 + y0_pre_uni)

# Check for equality
all(coef(ols) == coef(ols_uni))
```

[**Task 8:**]{style="color:#FF7E15"} Assign higher weight to more recent periods (no specific form required) and report the weights and ATT.

```{r}
#| code-fold: true

# Weights decreasing with distance to treatment period
a_adj <- seq(1, T_pre, 1)
a_adj <- T_pre*a_adj / sum(a_adj)
y0_pre_adj <- sweep(y0_pre, 1, a_adj, "*")
y1_pre_adj <- sweep(y1_pre, 1, a_adj, "*")

ols_adj <- lm(y1_pre ~ 0 + as.matrix(y0_pre_adj))

# Check for equality
w_adj <- coef(ols)
all(w_adj == w_ols)

# Show weights
print(as.data.frame(w_adj) |> arrange(-w_adj))
```

## Weight constraints

So far, we have not taken into account that, as discussed in the lecture, weights are subject to two conditions:

$\mathbf{W} = (w_2, \ldots, w_{N+1})'$, with $w_i \geq 0$ and $\sum_{i=2}^{N+1} w_i = 1$.

However, the sum of weights from before are:

```{r}
# Sum of weights
sum(w_ols)
sum(w_adj)
```

For optimization subject to constraints, we need to install and load `CVXR`, a package of convex optimization. Defining the objective and the constraint, we can solve for the optimal weights $w$ for the synthetic control unit.

```{r}
#| message: false
#| warning: false

library(CVXR)

# Optimization procedure
w <- Variable(ncol(y0_pre))
objective <- Minimize(sum_squares(y0_pre %*% w - y1_pre))
constraints <- list(sum(w) == 1, w >= 0)
problem <- Problem(objective, constraints)
w_star <- as.vector(solve(problem)$getValue(w))
```

Let's check whether the weights fulfill the constraints.

```{r}
# Check constraints
sum(w_star)
sum(w_star >= 0)
round(w_star, 2)

print(tibble(city = unique(ride[ride$treated == 0, ]$city), round(w_star, 2)))
```

[**Task 9:**]{style="color:#FF7E15"} Plot the treated unit and synthetic control prior to and after the treatment.

```{r}
#| code-fold: true

# Synthetic control
y_sc_star_pre <- y0_pre %*% w_star
y_sc_star_post <- y0_post %*% w_star

# Plot
plot_synth(y_sc_pre = y_sc_star_pre, y_sc_post = y_sc_star_post)
```

# Assignment

Coming soon.

::: assignment
...
<!-- Argue why not A/B test. -->
<!-- Summarize what we have done in the tutorial. -->
<!-- Pseudo effects for inference. -->
<!-- plot? -->
<!-- wrap into function -->
:::
